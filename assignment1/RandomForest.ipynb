{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# SENG 474\n",
    "# Assignment 1 - Problem 7\n",
    "# Nolan Kurylo\n",
    "# V00893175\n",
    "# References:\n",
    "\n",
    "1) https://pandas.pydata.org/pandas-docs/stable/reference/index.html\n",
    "\n",
    "2) https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The Training accuracy of the RandomForest: 87.8691503861881%\nThe Training error of the RandomForest: 12.1308496138119%\n\nThe Validation accuracy of the RandomForest: 88.34745762711864%\nThe Validation error of the RandomForest: 11.652542372881358%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, zero_one_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "df = pd.read_csv('elections_clean.csv') # create dataframe of csv\n",
    "\n",
    "\n",
    "label_vector = df.pop('Democrat') # this is the target/label vector\n",
    "\n",
    "feature_list = ['Education','Religion','EthnicMale','EthnicFemale'] # categorical features \n",
    "\n",
    "df = df[feature_list] # only split on categorical features (same as question 2)\n",
    "df = pd.get_dummies(df, feature_list) # one hot encoding of categorical features\n",
    "df['Democrat'] = label_vector # place label vector at the end of df\n",
    "\n",
    "\n",
    "training_set, validation_set, training_label, validation_label = train_test_split(df.drop('Democrat', axis=1), df['Democrat'], train_size=0.7) # split 70% traing, 30% validation\n",
    "RandomForest = RandomForestClassifier(n_estimators=50, max_depth=3, criterion='entropy') # generate random forest \n",
    "RandomForest.fit(training_set, training_label) # train the forest using the 70% training set\n",
    "\n",
    "training_prediction = RandomForest.predict(training_set) #predict accuracy of tree using training set\n",
    "validation_prediction = RandomForest.predict(validation_set) #predict accuracy of tree using validation set\n",
    "\n",
    "training_acc = accuracy_score(training_label, training_prediction) * 100 # training set accuracy\n",
    "training_err = zero_one_loss(training_label, training_prediction) * 100 # training set error\n",
    "\n",
    "validation_acc = accuracy_score(validation_label, validation_prediction) *100 # training set accuracy\n",
    "validation_err = zero_one_loss(validation_label, validation_prediction) * 100 # training set error\n",
    "\n",
    "\n",
    "print(\"The Training accuracy of the RandomForest: \" + str(training_acc) + \"%\")\n",
    "print(\"The Training error of the RandomForest: \" + str(training_err) + \"%\")\n",
    "print()\n",
    "\n",
    "print(\"The Validation accuracy of the RandomForest: \" + str(validation_acc) + \"%\")\n",
    "print(\"The Validation error of the RandomForest: \" + str(validation_err) + \"%\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Discussion of Random Forests\n",
    "The random forests actually end up having slightly worse results than singular Decision Trees. 50 decision trees in the forest pre-pruned to a depth of 3 produces a validation prediction accuracy of ~88% whereas a single Decision Tree (such as from question 2 or 4) has a prediction accuracy of ~91%. Random Forests have the purpose of increasing the accuracy of singular decision trees when the dataset the decision tree is being run on is not large enough to lead to a sufficient prediction. In the case of this large elections_clean dataset, there is enough data for a single decision tree to obtain a high level of prediction accuracy. In this case, the random forest does slightly worse as it is taking an average of numerous decision trees, inturn, being less accurate."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}