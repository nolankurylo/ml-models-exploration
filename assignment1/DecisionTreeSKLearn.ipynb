{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python390jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "\n",
    "\n",
    "# SENG 474\n",
    "# Assignment 1 - Problem 4\n",
    "# Nolan Kurylo\n",
    "# V00893175\n",
    "References:\n",
    "\n",
    "1) https://pandas.pydata.org/pandas-docs/stable/reference/index.html\n",
    "\n",
    "2) https://www.python-course.eu/Decision_Trees.php\n",
    "\n",
    "3) https://medium.com/@lope.ai/decision-trees-from-scratch-using-id3-python-coding-it-up-6b79e3458de4\n",
    "\n",
    "4) https://stackoverflow.com/\n",
    "\n",
    "5) https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The training accuracy of the DecisionTree: 91.41299409359382%\nThe training error of the DecisionTree: 8.587005906406176%\n\nThe validation accuracy of the DecisionTree: 91.10169491525424%\nThe validation error of the DecisionTree: 8.898305084745761%\n\nMaximum Depth of DecisionTree is: 8\n"
     ]
    }
   ],
   "source": [
    "# Only categorical features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, zero_one_loss\n",
    "\n",
    "np.random.seed(1337)\n",
    "\n",
    "df = pd.read_csv('elections_clean.csv') # create dataframe of csv\n",
    "\n",
    "label_vector = df.pop('Democrat') # this is the target/label vector\n",
    "\n",
    "feature_list = ['Education','Religion','EthnicMale','EthnicFemale'] # categorical features \n",
    "\n",
    "df = df[feature_list] # only split on categorical features (same as question 2)\n",
    "df = pd.get_dummies(df, feature_list) # one hot encoding of categorical features\n",
    "df['Democrat'] = label_vector # place label vector at the end of df\n",
    "\n",
    "\n",
    "training_set, validation_set, training_label, validation_label = train_test_split(df.drop('Democrat', axis=1), df['Democrat'], train_size=0.7) # split 70% traing, 30% validation\n",
    "DecisionTree = tree.DecisionTreeClassifier(criterion='entropy') # generate decision tree\n",
    "DecisionTree.fit(training_set, training_label) # train the tree using the 70% training set\n",
    "\n",
    "validation_prediction = DecisionTree.predict(validation_set) #predict accuracy of tree using validation set\n",
    "training_prediction = DecisionTree.predict(training_set) #predict accuracy of tree using training set\n",
    "\n",
    "training_acc = accuracy_score(training_label, training_prediction) * 100.0 # validation set accuracy\n",
    "training_err = zero_one_loss(training_label, training_prediction) * 100.0 # validation set error\n",
    "\n",
    "validation_acc = accuracy_score(validation_label, validation_prediction) * 100.0 # validation set accuracy\n",
    "validation_err = zero_one_loss(validation_label, validation_prediction) * 100.0 # validation set error\n",
    "\n",
    "print(\"The training accuracy of the DecisionTree: \" + str(training_acc) + \"%\")\n",
    "print(\"The training error of the DecisionTree: \" + str(training_err) + \"%\")\n",
    "print()\n",
    "\n",
    "print(\"The validation accuracy of the DecisionTree: \" + str(validation_acc) + \"%\")\n",
    "print(\"The validation error of the DecisionTree: \" + str(validation_err) + \"%\")\n",
    "print()\n",
    "\n",
    "max_depth = DecisionTree.get_depth()\n",
    "print(\"Maximum Depth of DecisionTree is: \" + str(max_depth))\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Tree Comparison \n",
    "In comparison to the Decision Tree built from scratch in Question 2, the structure and prediction accuracy of both tree are similar. When converting the\n",
    "same categorical features used in Question 2 to be one-hot-encoded features with the scikit-learn tree, both trees have a a maximum depth near 8 and a prediction accuracy\n",
    "around 91% and zero-one loss error of about 9%. They are similar since they use the same categorical features to split on and are both \"entropy\" based splitting algorithms, instead of using the gini coefficients. \n",
    "\n",
    "See above for code and results."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}